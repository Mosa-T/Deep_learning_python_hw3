{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ex3_DL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2ehdU4a-rlk"
      },
      "source": [
        "install the latest version of TorchText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvhFMtud9MKe",
        "outputId": "68f3bb9d-a202-4eec-dbb6-d825c2df3ae5"
      },
      "source": [
        "!pip install torchtext==0.4\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n",
            "\r\u001b[K     |██████▏                         | 10kB 20.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30kB 16.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4) (1.8.1+cu101)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.4) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4) (3.0.4)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.9.1\n",
            "    Uninstalling torchtext-0.9.1:\n",
            "      Successfully uninstalled torchtext-0.9.1\n",
            "Successfully installed torchtext-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Yti49xb-xud"
      },
      "source": [
        "Import all the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdz8-drZ-7yl"
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext.datasets import text_classification\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "from torch.utils.data.dataset import random_split\n",
        "import re\n",
        "from torchtext.data.utils import ngrams_iterator\n",
        "from torchtext.data.utils import get_tokenizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1mrxWmmA5k1"
      },
      "source": [
        "Define the ngrams and batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9kwscWwA2Mn"
      },
      "source": [
        "NGRAMS =3\n",
        "BATCH_SIZE = 16"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGdTW2BQBL5W"
      },
      "source": [
        " read the DBpedia dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crXHhqxXBCg-",
        "outputId": "f94d4c6b-5f6d-4846-d1b6-3d152d132b45"
      },
      "source": [
        "if not os.path.isdir('./.data'):\n",
        "    os.mkdir('./.data')\n",
        "train_dataset, test_dataset = text_classification.DATASETS['DBpedia'](\n",
        "    root='./.data', ngrams=NGRAMS, vocab=None)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dbpedia_csv.tar.gz: 68.3MB [00:00, 77.6MB/s]\n",
            "560000lines [01:07, 8303.71lines/s]\n",
            "560000lines [02:15, 4121.92lines/s]\n",
            "70000lines [00:16, 4180.27lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_74PBpwjB1tD"
      },
      "source": [
        "verify dataset length and number of labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_pIyDKpB-Mm",
        "outputId": "49ac851b-146d-4e2e-8da3-0e1a39a6d6ef"
      },
      "source": [
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "560000\n",
            "70000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja7NWMNZB_fu",
        "outputId": "43493ea0-0e0e-40a4-8f94-72443e3a8f03"
      },
      "source": [
        "print(len(train_dataset.get_labels()))\n",
        "print(len(test_dataset.get_labels()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14\n",
            "14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4-s2doVCiHG"
      },
      "source": [
        "speed up runtime with CUDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PY5ewogCpQe",
        "outputId": "0a76d2bb-da84-431a-e410-f261f550f075"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9COJ_LxSDAzn"
      },
      "source": [
        "define the model for the classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCBmedJrDPql"
      },
      "source": [
        "class TextSentiment(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)\n",
        "\n",
        "#print(model)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVtmFmJfMaot"
      },
      "source": [
        "initialize the hyperparameters and define the function to generate the training batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ3zOeuhMdZE",
        "outputId": "2e0719e2-f30d-4e64-fe45-cbf9301165f0"
      },
      "source": [
        "VOCAB_SIZE = len(train_dataset.get_vocab())\n",
        "EMBED_DIM = 32\n",
        "NUN_CLASS = len(train_dataset.get_labels())\n",
        "model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)\n",
        "\n",
        "def generate_batch(batch):\n",
        "    label = torch.tensor([entry[0] for entry in batch])\n",
        "    text = [entry[1] for entry in batch]\n",
        "    offsets = [0] + [len(entry) for entry in text]\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text = torch.cat(text)\n",
        "    return text, offsets, label\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TextSentiment(\n",
            "  (embedding): EmbeddingBag(19008016, 32, mode=mean)\n",
            "  (fc): Linear(in_features=32, out_features=14, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ-fwpOHM9Dc"
      },
      "source": [
        "define the function to train and test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdA6T-wVNDbj"
      },
      "source": [
        "def train_func(sub_train_):\n",
        "\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      collate_fn=generate_batch)\n",
        "    for i, (text, offsets, cls) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
        "        output = model(text, offsets)\n",
        "        loss = criterion(output, cls)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "    # Adjust the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
        "\n",
        "def test(data_):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
        "    for text, offsets, cls in data:\n",
        "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text, offsets)\n",
        "            loss = criterion(output, cls)\n",
        "            loss += loss.item()\n",
        "            acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "    return loss / len(data_), acc / len(data_)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afxx5ByZOD6N"
      },
      "source": [
        "train the model in 5 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxY1xV2jOMk1",
        "outputId": "ceebd874-ffc6-454a-fea9-f87a8def0af7"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "min_valid_loss = float('inf')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=4.0)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "\n",
        "train_len = int(len(train_dataset) * 0.95)\n",
        "sub_train_, sub_valid_ = \\\n",
        "    random_split(train_dataset, [train_len, len(train_dataset) - train_len])\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(sub_train_)\n",
        "    valid_loss, valid_acc = test(sub_valid_)\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 41 seconds\n",
            "\tLoss: 0.0098(train)\t|\tAcc: 95.6%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 97.9%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0022(train)\t|\tAcc: 99.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 98.2%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0010(train)\t|\tAcc: 99.7%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 98.3%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0005(train)\t|\tAcc: 99.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 98.3%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0003(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 98.4%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9E1jJe0RDuP"
      },
      "source": [
        " test model on test dataset, check the accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RebP7TB2RKZM",
        "outputId": "8f45b921-0dbf-43af-9943-9bbfefd91870"
      },
      "source": [
        "print('Checking the results of test dataset...')\n",
        "test_loss, test_acc = test(test_dataset)\n",
        "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset...\n",
            "\tLoss: 0.0000(test)\t|\tAcc: 94.9%(test)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWK7rk-fRmxe"
      },
      "source": [
        "test model on individual news text strings and predict the class label for that given news text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmzNXmKCRxl2"
      },
      "source": [
        "DBpedia_label = {0: 'Company',\n",
        "                1: 'EducationalInstitution',\n",
        "                2: 'Artist',\n",
        "                3: 'Athlete',\n",
        "                4: 'OfficeHolder',\n",
        "                5: 'MeanOfTransportation',\n",
        "                6: 'Building',\n",
        "                7: 'NaturalPlace',\n",
        "                8: 'Village',\n",
        "                9: 'Animal',\n",
        "                10: 'Plant',\n",
        "                11: 'Album',\n",
        "                12: 'Film',\n",
        "                13: 'WrittenWork'}\n",
        "\n",
        "def predict(text, model, vocab, ngrams):\n",
        "    tokenizer = get_tokenizer(\"basic_english\")\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor([vocab[token]\n",
        "                            for token in ngrams_iterator(tokenizer(text), ngrams)])\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() + 1\n",
        "vocab = train_dataset.get_vocab()\n",
        "model = model.to(\"cpu\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BkjbUPGSZfI"
      },
      "source": [
        "Taking random texts from the test data and checking the predicted class label.\n",
        "\n",
        "First prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOuURs9MSbfO",
        "outputId": "07c483fb-0136-410a-beec-1ca90e9dd5be"
      },
      "source": [
        "ex_text_str = \"Brekke Church (Norwegian: Brekke kyrkje) is a parish church in Gulen Municipality in Sogn og Fjordane county, Norway. It is located in the village of Brekke. The church is part of the Brekke parish in the Nordhordland deanery in the Diocese of BjÃ¸rgvin. The white, wooden church, which has 390 seats, was consecrated on 19 November 1862 by the local Dean Thomas Erichsen. The architect Christian Henrik Grosch made the designs for the church, which is the third church on the site.\"\n",
        "\n",
        "print(\"This is a %s class\" %DBpedia_label[predict(ex_text_str, model, vocab, 2)])\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a NaturalPlace class\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNwa7d4JT4rO"
      },
      "source": [
        "Second Prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tfr4_JfsT7s2",
        "outputId": "45ef8989-cab2-4a33-c730-52fb01457f47"
      },
      "source": [
        "ex_text_str2 = \"Cerithiella superba is a species of very small sea snail, a marine gastropod mollusk in the family Newtoniellidae. This species is known from European waters. It was described by Thiele, 1912.\"\n",
        "\n",
        "print(\"This text belongs to %s class\" %DBpedia_label[predict(ex_text_str2, model, vocab, 2)])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This text belongs to Plant class\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDmps7fYUicu"
      },
      "source": [
        "Third Prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVZF0ESmUjPO",
        "outputId": "c74320fe-0f23-432f-90ad-bf662420596f"
      },
      "source": [
        "ex_text_str3 = \"  Nithari is a village in the western part of the state of Uttar Pradesh India bordering on New Delhi. Nithari forms part of the New Okhla Industrial Development Authority's planned industrial city Noida falling in Sector 31. Nithari made international news headlines in December 2006 when the skeletons of a number of apparently murdered women and children were unearthed in the village.\"\n",
        "\n",
        "print(\"This text belongs to %s class\" %DBpedia_label[predict(ex_text_str3, model, vocab, 2)])\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This text belongs to Animal class\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNHMQVSZqYrc"
      },
      "source": [
        "Randoms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DMq8e-9Ya2W",
        "outputId": "df81fcd5-471f-4a36-bdfc-4045a5c54bcb"
      },
      "source": [
        "\n",
        "ex_text_str4 = \" Football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal. Unqualified, the word football normally means the form of football that is the most popular where the word is used. Sports commonly called football include association football (known as soccer in\"\n",
        "\n",
        "print(\"This text belongs to %s class\" %DBpedia_label[predict(ex_text_str4, model, vocab, 2)])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This text belongs to Album class\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PPeS2ZkjSd5",
        "outputId": "5a58c951-ccb5-48a0-9347-78d6b1daf338"
      },
      "source": [
        "ex_text_str5 = \"  Raining Stones is a 1993 film directed by Ken Loach and starring Bruce Jones, Julie Brown, Ricky Tomlinson, Tom Hickey and Gemma Phoenix. It tells the story of a man who cannot afford to buy his daughter a First Communion dress, and makes disastrous choices in trying to raise the money. The film won the Jury Prize at the 1993 Cannes Film Festival\"\n",
        "\n",
        "print(\"This text belongs to %s class\" %DBpedia_label[predict(ex_text_str5, model, vocab, 2)])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This text belongs to WrittenWork class\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDgJz1UZjtcy",
        "outputId": "f6d2d9d9-d677-49c4-f8fc-10bd210cfaf8"
      },
      "source": [
        "ex_text_str6 = \"`House Arrest` is a song by British dance group Krush. Released as a single in 1987, it is hailed as one of the forerunners of the British house music scene and became the group's biggest hit, reaching the top 20 charts in at least 8 countries in Europe. The song peaked at No. 3 on the\"\n",
        "\n",
        "print(\"This text belongs to %s class\" %DBpedia_label[predict(ex_text_str6, model, vocab, 2)])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This text belongs to Film class\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TWVArvdjeUU",
        "outputId": "06a92487-828c-4227-aac7-14d89e3a8ec5"
      },
      "source": [
        "ex_text_str7 = \" clowns\"\n",
        "\n",
        "print(\"This text belongs to %s class\" %DBpedia_label[predict(ex_text_str7, model, vocab, 2)])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This text belongs to OfficeHolder class\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}